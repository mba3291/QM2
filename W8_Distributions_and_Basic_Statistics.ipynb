{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mba3291/QM2/blob/main/W8_Distributions_and_Basic_Statistics.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lads9rv6exJ-"
      },
      "source": [
        "# Difference in Differences\n",
        "\n",
        "## *Workshop 08*  [![Open In Colab](https://github.com/oballinger/QM2/blob/main/colab-badge.png?raw=1)](https://colab.research.google.com/github/oballinger/QM2/blob/main/notebooks_2025_option_2/W08.%20Diff-in-Diff.ipynb)\n",
        "\n",
        "### Aims:\n",
        "\n",
        "This workshop builds on last week's material, replicating analysis in published academic research on the relationship between minimum wages and unemployment."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5KugRUBXRUqf"
      },
      "source": [
        "As always we'll start by importing the libraries I need"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5ERdQ-QjexKB"
      },
      "outputs": [],
      "source": [
        "#!pip install linearmodels\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import plotly\n",
        "import plotly.express as px\n",
        "import warnings\n",
        "from statsmodels.formula.api import ols\n",
        "from statsmodels.iolib.summary2 import summary_col\n",
        "import matplotlib.pyplot as plt\n",
        "import statsmodels.api as sm\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "sns.set(font_scale=1.5)\n",
        "sns.set_style(\"white\")\n",
        "plt.rcParams['figure.figsize'] = (12, 8)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1pKixnxlvtEg"
      },
      "source": [
        "----------------------\n",
        "## Panel Regression\n",
        "\n",
        "[Surveys](https://www.pewresearch.org/politics/2012/04/17/with-voters-focused-on-economy-obama-lead-narrows/) indicate that \"jobs\" are consistently one of the most important issues among voters in U.S. presidential elections, and that Republicans are [typically perceived](https://thehill.com/homenews/campaign/3700047-republicans-hold-14-point-advantage-on-which-party-would-do-better-job-on-economy-poll/) as better in handling the economy than Democrats. An [article](https://www.nbcnews.com/news/us-news/where-did-trump-make-election-gains-unemployment-data-tells-surprising-n1247935) in NBC claims that \"analysis of unemployment and voting data found that the presidentâ€™s share of the vote held steady or increased in each of the 20 counties with the highest rise in unemployment from September 2019 to September 2020. And his vote share improved by 1 percentage point or more in 70 of the 100 hardest-hit counties.\" Let's look into this.\n",
        "\n",
        "\n",
        "### Data Collection\n",
        "\n",
        "There are only 50 states in the U.S. but there are over 3000 counties-- this allows us to increase our sample size and perform a more fine-grained analysis. This is particularly important if we're interested in investigating the relationship between unemployment and voting behaviour, because of the urban-rural divide. For example, with in the state of New York there are probably vast differences in social and economic factors relevant to voting behaviour between Manhattan and very rural areas; this variation is lost when we look at aggregate state-level resutls, but visible when we look at the county-level. As such, in addition to the datasets we've just imported, we're going to be downloading county-level unemployment data straight from the BLS using the loop below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B7csLwLkvtEg"
      },
      "outputs": [],
      "source": [
        "counties=pd.read_csv('https://storage.googleapis.com/qm2/wk10/county_labor.csv', converters={'county_fips': str})\n",
        "counties.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Hy4O5DNvtEg"
      },
      "source": [
        "Part of the cleaning process in the cell above involves the creation of a column called \"county_fips\"-- this stands for [Federal Information Processing System](https://transition.fcc.gov/oet/info/maps/census/fips/fips.txt#:~:text=FIPS%20codes%20are%20numbers%20which,to%20which%20the%20county%20belongs.). This is a code that uniquely identifies states and counties in the U.S. A two digit FIPS code identifies states (e.g. 01: Alabama, 02: Alaska, etc.) and a five digit fips code identifies counties (e.g. 010001: Atauga County, Alabama; 02068: Denali Borough, Alaska). Notice, the first two digits of the five-digit county FIPS code indicates the state. Boring, yes, but these codes are imperative in allowing us to join county- and state- level datasets from different sources quicky and easily. Imagine what a nightmare it would be to try to join them using the names of the counties, having to deal with capitalizations, punctuation, etc. Yikes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "55doH3IYvtEg"
      },
      "source": [
        "### Maps\n",
        "\n",
        "Great-- we've now got clean, county-level unemployment and population data spanning from 1990-2022 on an annual basis. Lets make a map to explore the spatial distribution of unemployment across time in the U.S. In order to do that, we're going to need a spatial file that tells us the shapes of the counties; I've imported it as a variable called `county_polygons`. We're then going to create an  map using the [Plotly](https://plotly.com/python/) library, which is great for making pretty, interactive maps and plots. It will have a slider on the bottom that lets us view unemployment in different years. It's doing quite a bit under the hood so it will take some time to plot. Be patient."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o3hAiz46vtEg"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "!mkdir data\n",
        "!mkdir data/wk10/\n",
        "!curl https://storage.googleapis.com/qm2/wk10/geojson-counties-fips.json -o data/wk10/geojson-counties-fips.json\n",
        "\n",
        "county_polygons = json.load(open(\"data/wk10/geojson-counties-fips.json\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 401
        },
        "id": "8_YQ3qtRvtEh",
        "outputId": "f9f25299-3a9b-4ec9-b906-8aedeb693420"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2811143644.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mplot_sample\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcounties\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcounties\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'year'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;36m2007\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# subset the data to only include years after 2007 -- it would take too long to plot all of the data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m px.choropleth( # plot a choropleth map using the plotly express (px) library\n\u001b[0m\u001b[1;32m      4\u001b[0m                 \u001b[0mplot_sample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m# load the dataframe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                 \u001b[0mlocations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'county_fips'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m# set the location column to the state code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/IPython/core/displayhook.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, result)\u001b[0m\n\u001b[1;32m    260\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_displayhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite_output_prompt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m             \u001b[0mformat_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmd_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_format_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    263\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_user_ns\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfill_exec_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/IPython/core/displayhook.py\u001b[0m in \u001b[0;36mcompute_format_data\u001b[0;34m(self, result)\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m         \"\"\"\n\u001b[0;32m--> 151\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshell\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisplay_formatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m     \u001b[0;31m# This can be set to True by the write_output_prompt method in a subclass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/IPython/core/formatters.py\u001b[0m in \u001b[0;36mformat\u001b[0;34m(self, obj, include, exclude)\u001b[0m\n\u001b[1;32m    144\u001b[0m         \u001b[0mmd_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mipython_display_formatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m             \u001b[0;31m# object handled itself, don't proceed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<decorator-gen-4>\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, obj)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/IPython/core/formatters.py\u001b[0m in \u001b[0;36mcatch_format_error\u001b[0;34m(method, self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    222\u001b[0m     \u001b[0;34m\"\"\"show traceback on failed format call\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m         \u001b[0;31m# don't warn on NotImplementedErrors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/IPython/core/formatters.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    916\u001b[0m             \u001b[0mmethod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_real_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_method\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 918\u001b[0;31m                 \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    919\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    920\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/plotly/basedatatypes.py\u001b[0m in \u001b[0;36m_ipython_display_\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    831\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrenderers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrender_on_display\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mpio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrenderers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefault\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 832\u001b[0;31m             \u001b[0mpio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    833\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    834\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrepr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/plotly/io/_renderers.py\u001b[0m in \u001b[0;36mshow\u001b[0;34m(fig, renderer, validate, **kwargs)\u001b[0m\n\u001b[1;32m    381\u001b[0m     \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m     \"\"\"\n\u001b[0;32m--> 383\u001b[0;31m     \u001b[0mfig_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidate_coerce_fig_to_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    384\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    385\u001b[0m     \u001b[0;31m# Mimetype renderers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/plotly/io/_utils.py\u001b[0m in \u001b[0;36mvalidate_coerce_fig_to_dict\u001b[0;34m(fig, validate)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBaseFigure\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mfig_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mvalidate\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/plotly/basedatatypes.py\u001b[0m in \u001b[0;36mto_dict\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   3306\u001b[0m         \u001b[0;31m# Frame key is only added if there are any frames\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3307\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"data\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"layout\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlayout\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3308\u001b[0;31m         \u001b[0mframes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_props\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mframe\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_frame_objs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3309\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3310\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mframes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/copy.py\u001b[0m in \u001b[0;36mdeepcopy\u001b[0;34m(x, memo, _nil)\u001b[0m\n\u001b[1;32m    134\u001b[0m     \u001b[0mcopier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_deepcopy_dispatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcopier\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    137\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0missubclass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/copy.py\u001b[0m in \u001b[0;36m_deepcopy_list\u001b[0;34m(x, memo, deepcopy)\u001b[0m\n\u001b[1;32m    194\u001b[0m     \u001b[0mappend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m         \u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_deepcopy_list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/copy.py\u001b[0m in \u001b[0;36mdeepcopy\u001b[0;34m(x, memo, _nil)\u001b[0m\n\u001b[1;32m    134\u001b[0m     \u001b[0mcopier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_deepcopy_dispatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcopier\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    137\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0missubclass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/copy.py\u001b[0m in \u001b[0;36m_deepcopy_dict\u001b[0;34m(x, memo, deepcopy)\u001b[0m\n\u001b[1;32m    219\u001b[0m     \u001b[0mmemo\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 221\u001b[0;31m         \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_deepcopy_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/copy.py\u001b[0m in \u001b[0;36mdeepcopy\u001b[0;34m(x, memo, _nil)\u001b[0m\n\u001b[1;32m    134\u001b[0m     \u001b[0mcopier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_deepcopy_dispatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcopier\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    137\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0missubclass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/copy.py\u001b[0m in \u001b[0;36m_deepcopy_list\u001b[0;34m(x, memo, deepcopy)\u001b[0m\n\u001b[1;32m    194\u001b[0m     \u001b[0mappend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m         \u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_deepcopy_list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/copy.py\u001b[0m in \u001b[0;36mdeepcopy\u001b[0;34m(x, memo, _nil)\u001b[0m\n\u001b[1;32m    134\u001b[0m     \u001b[0mcopier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_deepcopy_dispatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcopier\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    137\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0missubclass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/copy.py\u001b[0m in \u001b[0;36m_deepcopy_dict\u001b[0;34m(x, memo, deepcopy)\u001b[0m\n\u001b[1;32m    219\u001b[0m     \u001b[0mmemo\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 221\u001b[0;31m         \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_deepcopy_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/copy.py\u001b[0m in \u001b[0;36mdeepcopy\u001b[0;34m(x, memo, _nil)\u001b[0m\n\u001b[1;32m    134\u001b[0m     \u001b[0mcopier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_deepcopy_dispatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcopier\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    137\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0missubclass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/copy.py\u001b[0m in \u001b[0;36m_deepcopy_dict\u001b[0;34m(x, memo, deepcopy)\u001b[0m\n\u001b[1;32m    219\u001b[0m     \u001b[0mmemo\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 221\u001b[0;31m         \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_deepcopy_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/copy.py\u001b[0m in \u001b[0;36mdeepcopy\u001b[0;34m(x, memo, _nil)\u001b[0m\n\u001b[1;32m    134\u001b[0m     \u001b[0mcopier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_deepcopy_dispatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcopier\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    137\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0missubclass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/copy.py\u001b[0m in \u001b[0;36m_deepcopy_list\u001b[0;34m(x, memo, deepcopy)\u001b[0m\n\u001b[1;32m    194\u001b[0m     \u001b[0mappend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m         \u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_deepcopy_list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/copy.py\u001b[0m in \u001b[0;36mdeepcopy\u001b[0;34m(x, memo, _nil)\u001b[0m\n\u001b[1;32m    134\u001b[0m     \u001b[0mcopier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_deepcopy_dispatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcopier\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    137\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0missubclass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/copy.py\u001b[0m in \u001b[0;36m_deepcopy_dict\u001b[0;34m(x, memo, deepcopy)\u001b[0m\n\u001b[1;32m    219\u001b[0m     \u001b[0mmemo\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 221\u001b[0;31m         \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_deepcopy_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/copy.py\u001b[0m in \u001b[0;36mdeepcopy\u001b[0;34m(x, memo, _nil)\u001b[0m\n\u001b[1;32m    134\u001b[0m     \u001b[0mcopier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_deepcopy_dispatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcopier\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    137\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0missubclass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/copy.py\u001b[0m in \u001b[0;36m_deepcopy_dict\u001b[0;34m(x, memo, deepcopy)\u001b[0m\n\u001b[1;32m    219\u001b[0m     \u001b[0mmemo\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 221\u001b[0;31m         \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_deepcopy_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/copy.py\u001b[0m in \u001b[0;36mdeepcopy\u001b[0;34m(x, memo, _nil)\u001b[0m\n\u001b[1;32m    134\u001b[0m     \u001b[0mcopier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_deepcopy_dispatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcopier\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    137\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0missubclass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/copy.py\u001b[0m in \u001b[0;36m_deepcopy_list\u001b[0;34m(x, memo, deepcopy)\u001b[0m\n\u001b[1;32m    194\u001b[0m     \u001b[0mappend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m         \u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_deepcopy_list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/copy.py\u001b[0m in \u001b[0;36mdeepcopy\u001b[0;34m(x, memo, _nil)\u001b[0m\n\u001b[1;32m    134\u001b[0m     \u001b[0mcopier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_deepcopy_dispatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcopier\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    137\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0missubclass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/copy.py\u001b[0m in \u001b[0;36m_deepcopy_list\u001b[0;34m(x, memo, deepcopy)\u001b[0m\n\u001b[1;32m    194\u001b[0m     \u001b[0mappend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m         \u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_deepcopy_list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/copy.py\u001b[0m in \u001b[0;36mdeepcopy\u001b[0;34m(x, memo, _nil)\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0mmemo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m     \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    128\u001b[0m     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_nil\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_nil\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "plot_sample=counties[counties['year']>2007] # subset the data to only include years after 2007 -- it would take too long to plot all of the data\n",
        "\n",
        "px.choropleth( # plot a choropleth map using the plotly express (px) library\n",
        "                plot_sample, # load the dataframe\n",
        "                locations='county_fips', # set the location column to the state code\n",
        "                geojson=county_polygons, # set the location mode to USA states (you could add your own custom geojson/spatial file here)\n",
        "                scope='usa', # set the scope to the USA, so that it only plots the states\n",
        "                color=\"unemployment\", # set the color of the states to correspond to the unemployment rate\n",
        "                animation_frame=plot_sample[\"year\"].astype(str), # set the animation frame to the date, creating a slider at the bottom of the map\n",
        "                color_continuous_scale=px.colors.sequential.Viridis, # set the color scale to Viridis, a commonly used color scale\n",
        "                range_color=[0, 10], # set the range of the color scale to 0-10\n",
        "                height=1000) # set the height of the map to 1000 pixels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_h96vtYYvtEi"
      },
      "source": [
        "This map is interactive-- meaning you can zoom in, pan around, and hover over it to get further information on the unemployment level in each county. You can also use the slider at the bottom to toggle between different years; if you move the slider from 2008 to 2009, you'll see lots of yellow suddenly appearing. A similar thing happens between 2019 and 2020. What's going on? Play around with this map for a second, and make note of spatial and temporal trends in unemployment."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oM__qPtcv8Yx"
      },
      "source": [
        "**General Spatial and Temporal Trends Observed:**\n",
        "\n",
        "\n",
        "* Spatially, regional differences persist despite economic stability. Certain areas consistently maintain higher or lower unemployment rates due to factors such as dominant industries, demographics, or remoteness.\n",
        "* Temporally, unemployment rates fluctuate with economic cycles: darker colors indicate lower unemployment during economic expansions, while lighter colors indicate higher unemployment during recessions.\n",
        "\n",
        "\n",
        "Some of the patterns observed are:\n",
        "\n",
        "\n",
        "* Generally lower unemployment in densely populated, economically diverse urban areas (though these can also be severely affected during specific downturns)\n",
        "* Higher unemployment in rural areas or regions with declining traditional industries\n",
        "* Pattern differences between coastal and interior regions due to varying economic climates\n",
        "\n",
        "\n",
        "Accordingly, the slider visualizes the geographical impact of historical economic events on employment, including the Great Recession (2008-2011) and the COVID-19 pandemic (2019-2020).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CdWgqJnxv7Qw"
      },
      "source": [
        "Now we're going to do the same thing for the elections data, which I've taken the liberty of cleaning. Let's load it up as a dataframe called `elections`, and make another map in which we plot vote shares in various elections such that red shows republican support, and blue shows democratic support."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9ZRFHRhWvtEi"
      },
      "outputs": [],
      "source": [
        "elections=pd.read_csv('https://storage.googleapis.com/qm2/wk10/elections.csv',converters={'county_fips': str})\n",
        "px.choropleth(\n",
        "                elections,\n",
        "                locations='county_fips',\n",
        "                geojson=county_polygons,\n",
        "                scope='usa',\n",
        "                color=\"r_votes\",\n",
        "                animation_frame=elections[\"year\"].astype(str),\n",
        "                color_continuous_scale=px.colors.diverging.balance,\n",
        "                range_color=[20, 80],\n",
        "                height=1000)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JpOoDHfnwBYT"
      },
      "source": [
        "Explore the map above. What do you notice about republican vote share, particularly as it relates to the previous map of unemployment?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Jd8Ak6gwDPK"
      },
      "source": [
        "An **inverse relationship** emerges: areas with lower unemployment rates  (denoted by darker greens/blues on the unemployment map) often show lower Republican vote shares (bluer areas on the election map), while areas with higher unemployment (yellows/lighter greens), particularly rural regions, tend to show higher Republican support (redder).\n",
        "\n",
        "This pattern reveals that urban and suburban counties with lower unemployment typically vote less Republican, while rural counties with higher unemployment vote more Republican.\n",
        "\n",
        "Consequently, the intersection between socio-economic factors and the urban-rural divide reveals how it shapes voting patterns.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "81_LzKM4vtEi"
      },
      "source": [
        "Now we've got two datasets-- one on unemployment and another on election results. We want to merge them but CAREFUL: each row corresponds to the value of a variable $x$ in county $i$ and time $t$ (so, $x_{it}$); for example, the value in the first row of our dataset under the unemployment column would be $unemployment_{01001, 2000}$; i.e., the unemployment rate in Atauga County, Alabama (FIPS code 01001), in the year 2000. When our data has this structure ($x_{it}$), we call it **panel data**. It must be handled differently from **cross sectional data** ($x_i$), from merging to estimation.\n",
        "\n",
        "We can't just merge on $i$ or $t$, we need to merge on both. We can do so as follows:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9zDXYfpLvtEi"
      },
      "outputs": [],
      "source": [
        "df_c=pd.merge(elections,counties, on=['county_fips','year'])\n",
        "df_c.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0GALIA9KvtEi"
      },
      "source": [
        "### Exercise\n",
        "\n",
        "OK. Our data is clean and ready for analysis. Because we're going to be investigating the relationship between unempoyment rates and republican voteshare via a regression model, we're going to need to follow the four steps of regression modeling from [last week](https://oballinger.github.io/QM2/notebooks/W09.%20Linear%20Regression.html).\n",
        "\n",
        "First, formulate a research question (complete with null and alternative hypothesis), and then follow these steps for our dataset, `df_c` (bonus points if you account for the influence of population).\n",
        "\n",
        "1. Summary Statistics\n",
        "    * Table of Summary Statistics\n",
        "2. Visualisation\n",
        "    * Exploratory Plots\n",
        "3. Assumptions\n",
        "    * A. Independence\n",
        "    * B. Heteroscedasticity: Regression plots + Q-Q plot\n",
        "    * C. Multicollinearity: VIF + Correlation Matrix\n",
        "4. Regression\n",
        "    * Regression Table\n",
        "\n",
        "For the moment, when you run the regression, ignore the fact that we have panel data and just run a regular regression of the form\n",
        "$$\\huge Y= \\beta_0 + \\beta_1X+\\epsilon $$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uTj93aCGw4eD"
      },
      "source": [
        "**Research Question:** How do county-level unemployment rates and population density influence Republican vote share in US presidential elections?\n",
        "\n",
        "**Null Hypothesis (Hâ‚€): Î²1â€‹=0**\n",
        "\n",
        "There is no significant relationship between county-level unemployment rates, population size, and Republican vote share in US presidential elections.\n",
        "\n",
        "Specifically, changes in unemployment rates or population size do not significantly affect the Republican vote share.\n",
        "\n",
        "**Alternative Hypothesis (H1): Î²1â‰ 0**\n",
        "\n",
        "A significant relationship exists between county-level unemployment rates, population size, and Republican vote share in US presidential elections.\n",
        "\n",
        "Specifically, our preliminary visual analysis hypothesizes that higher unemployment rates will be negatively correlated with Republican vote share (Î²â‚ < 0), while larger population sizes will be inversely related to Republican vote share (Î²â‚‚ < 0)\n",
        "\n",
        "Accordingly, this would reflect the aforementioned persistent urban-rural divides in economic conditions and voting patterns."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cqdltB0c3IKN"
      },
      "source": [
        "# Summary Statistics\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iOnXL3WJxghM"
      },
      "outputs": [],
      "source": [
        "df_c[['unemployment','r_votes','population']].describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CHUJDR46yt0m"
      },
      "source": [
        "This table shows the average, spread, and range of unemployment rates, Republican vote share, and population across U.S. counties. Large variation exists in unemployment and population, suggesting substantial differences in economic conditions and county characteristics."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lb5QPNBG3Npw"
      },
      "source": [
        "# Visualisation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w_cApLpGyu_v"
      },
      "outputs": [],
      "source": [
        "sns.scatterplot(data=df_c, x='unemployment', y='r_votes')\n",
        "plt.xlabel(\"Unemployment rate\")\n",
        "plt.ylabel(\"Republican vote share\")\n",
        "plt.title(\"Unemployment vs Republican Vote Share\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N0Wf61_3y0XV"
      },
      "source": [
        "The scatterplot reveals a negative relationship between unemployment rates and Republican vote share, suggesting that counties with higher unemployment tend to show lower Republican support."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a8FPRXZk01XF"
      },
      "outputs": [],
      "source": [
        "sns.scatterplot(data=df_c, x='unemployment', y='r_votes', size='population', alpha=0.5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TBjVI6RW1yCZ"
      },
      "source": [
        "This scatterplot, with point size scaled by population, provides additional insight into the relationship between unemployment and Republican vote share. The larger points (highly populated counties) tend to concentrate in the lower-left region, indicating lower unemployment and lower Republican support. This pattern aligns with urban areas' tendency toward Democratic voting and their distinct economic profiles."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t2dQZCeY2P__"
      },
      "source": [
        "# Assumptions\n",
        "**A. Independence:**\n",
        "\n",
        "Each county-year observation is assumed to be independent. This assumption does not fully hold given the panel structure of the data, but I proceeded with it as instructed."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gcwhQ4NR2rGo"
      },
      "source": [
        "**B. Heteroskedasticity**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z9QNMDx-13gQ"
      },
      "outputs": [],
      "source": [
        "model = ols(\"r_votes ~ unemployment + population\", data=df_c).fit()\n",
        "sns.residplot(x=model.fittedvalues, y=model.resid)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gNtx2Mey47k8"
      },
      "source": [
        "The above residual plot shows a pattern where the spread of residuals changes across the fitted values. It appears to widen as the fitted values increase, resembling a 'fan' or 'cone' shape. This indicates heteroscedasticity, meaning the variance of the errors is not constant. This suggests that the model's standard errors (and thus p-values and confidence intervals) might be unreliable"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QMdyV9I820Uv"
      },
      "outputs": [],
      "source": [
        "sm.qqplot(model.resid, line='45')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OLA-O_XM4hRN"
      },
      "source": [
        "The Q-Q plot shows significant deviations from the 45-degree line, particularly in both tails, suggesting the residuals have heavier tails than a normal distribution. This indicates that the residuals are not normally distributed, violating the normality assumption of OLS regression."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CjI9YqLz26Oz"
      },
      "source": [
        "**C. Multicollinearity**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IuIq5eLi284M"
      },
      "outputs": [],
      "source": [
        "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
        "\n",
        "X = df_c[['unemployment','population']]\n",
        "X = sm.add_constant(X)\n",
        "\n",
        "pd.Series([variance_inflation_factor(X.values, i) for i in range(X.shape[1])],\n",
        "          index=X.columns)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ViXJ6ixf5Y9K"
      },
      "source": [
        "The VIF diagnostics reveal:\n",
        "\n",
        "*   Unemployment: VIF = 1.001567\n",
        "*   Population: VIF = 1.001567\n",
        "\n",
        "These values are both extremely close to 1, indicating virtually no multicollinearity between the two predictors. This confirms that unemployment and population are sufficiently independent, allowing the model to isolate their individual effects on Republican vote share without confounding."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QgJA4AbD2_3Q"
      },
      "source": [
        "# Regression\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gxmz_QMM3WeM"
      },
      "outputs": [],
      "source": [
        "model = ols(\"r_votes ~ unemployment\", data=df_c).fit()\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WvyeSZTG3ZjK"
      },
      "outputs": [],
      "source": [
        "model2 = ols(\"r_votes ~ unemployment + population\", data=df_c).fit()\n",
        "model2.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y0vr5moF7OZm"
      },
      "source": [
        "The unemployment coefficient (Î²â‚ = -1.5355, p < 0.001) indicates that each percentage point increase in unemployment is associated with approximately a 1.54 percentage point decrease in Republican vote share, controlling for population. This statistically significant negative relationship confirms the inverse association hypothesized from preliminary visual analysis."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cYYCy5_hw3LF"
      },
      "source": [
        "### Accounting for Space and Time\n",
        "\n",
        "If you've done things correctly, you'll notice two things. First, the appears to be a generally negative relationship between unemployment and republican voteshare; in other words, places with higher unemployment tend to vote *against* republicans. Second, we've egregiously violated the independence assumption. We have repeat observations of the same individuals (counties) over time. As such, this result may be biased unless we account for space and time.\n",
        "\n",
        "As we saw in the lecture, panel data actually contains *two* sources of variation: differences *between* individuals (in this case, counties), and *within* individuials. So, a simple research question such as \"Does unemployment increase republican voteshare\" is actually two different questions:\n",
        "\n",
        "1. Does a higher level of unemployment lead to higher republican vote shares **between counties**?\n",
        "2. Does an *increase* in the unemployment rate over time lead to an *increase* in republican vote shares **within counties**?\n",
        "\n",
        "Neither is more important than the other, but we must be careful not to conflate them as they are very different questions. A straighforward way of answering the first question would be to get rid of the time dimension in our data by running a separate regression for each year:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BRKVc6fsvtEi"
      },
      "outputs": [],
      "source": [
        "models=[] # create empty list to store the models\n",
        "names=[] # create empty list to store the names of the models\n",
        "years=df_c['year'].unique()\n",
        "\n",
        "for year in years: # loop through years from 2000 to 2020 in increments of 4\n",
        "    election=df_c[df_c['year']==year] # subset the data to only include the year of interest\n",
        "    model= ols('r_votes ~ unemployment + population', data=election).fit() # run a regression of the republican vote share on the unemployment rate\n",
        "    models.append(model) # append the model to the list of models\n",
        "    names.append(str(year)) # append the name of the model to the list of names\n",
        "\n",
        "table=summary_col( # create a regression table\n",
        "    models, # pass the models to the summary_col function\n",
        "    stars=True, # add stars denoting the p-values of the coefficient to the table; * p<0.05, ** p<0.01, *** p<0.001\n",
        "    float_format='%0.3f', # set the decimal places to 3\n",
        "    model_names=names, # set the names of the model\n",
        "    info_dict = {\"N\":lambda x: \"{0:d}\".format(int(x.nobs))}) # add the number of observations to the table\n",
        "\n",
        "print(table) # print the table"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B52UX5YLvtEi"
      },
      "source": [
        "This table is pretty informative. Using what we learned from last week, we can say that for the 2020 election,\n",
        "\n",
        "* A 1% increase in the unemployment rate was associated with a 2.3% *decrease* in republican voteshare.\n",
        "* A 1000-person increase in population was associated with 0.029% decrease in republican voteshare.\n",
        "* both of these results are statistically signifiant at the 0.01 level.\n",
        "* 23% of the variation in republican voteshare can be explained by unemployment and population.\n",
        "\n",
        "Crucially, \"increase\" in this context pertains to *differences in between counties*!\n",
        "\n",
        "We can also compare these results across different elections. The coefficient for the unemployment variable in 2020 is over twice the size of the same coefficient in 2016! So it looks like actually unemployment and republican voteshare are *negatively* related, contrary to popular belief.\n",
        "\n",
        "But is this the whole story?\n",
        "\n",
        "Below, i've isolated West Virginia, one of the states with the highest unemployment rates in America. Instead of drawing a new regression line every year, i've drawn a new regression line for each county over the six elections.         "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r5C7rDK9vtEi"
      },
      "outputs": [],
      "source": [
        "west_virginia=df_c[(df_c['state']==54)]\n",
        "sns.lmplot(data=west_virginia, x='unemployment', y='r_votes', ci=None, hue='county', height=10, legend=False, palette='husl', scatter_kws={'alpha':.3})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hZmMgXKQvtEi"
      },
      "source": [
        "Within a given county, an increase in the unemployment rate is associated with an **increase** in republican voteshare! This is where the second question comes in (variation within counties).\n",
        "\n",
        "We got away with doing a series of cross-sectional analyses (a new regression for each election) because we have over 3000 counties, so $n>3000$ for each of those regressions (though even so, we're still splitting our data up and it would be better to leverage the full dataset of >18000 observations in one regression). It also provides relatively useful information about the importance of unemployment across the country for each election. We can't really apply the same thinking to this situation, since we only have six time periods. If we ran a separate regression for each county, we would only have six observations per regression-- nowhere near enough to satisfy the central limit theorem (at least n>30). The insights would also be of limited utility; we would get over 3000 unique estimates for the realtionship between county-level employment and election results. Imagine trying to fit *that* into one table.\n",
        "\n",
        "Luckily, there's a way of modeling this relationship that allows us to account for differences in between counties, while also capturing the variation within counties. This is called a **Fixed Effect regression**\n",
        "\n",
        "> **Fixed Effects Models**: In experimental research, unmeasured differences between subjects are often controlled for via random assignment to treatment and control groups. Hence, even if a variable like Socio-Economic Status is not explicitly measured, because of random assignment, we can be reasonably confident that the effects of SES are approximately equal for all groups. Of course, random assignment is usually not possible with most survey research. If we want to control for the effect of a variable, we must explicitly measure it. If we donâ€™t measure it, we canâ€™t control for it. In practice, there will almost certainly be some variables we have failed to measure (or have measured poorly), so our models will likely suffer from some degree of omitted variable bias.\n",
        ">When we have panel data (the same people/states/counties. etc. measured at two or more points in time) another alternative presents itself: we can use the subjects as their own controls. With panel data we can control for stable characteristics (i.e. characteristics that do not change across time) whether they are measured or not. These include such things as sex, race, and ethnicity for individuals, or urban/rural, topography, economic structure for geographic areas. The idea is that, whatever effect these variables have at one point in time, they will have the same effect at a different point in time because the values of such variables do not change.\n",
        "\n",
        "A fixed effect regression takes the following form:\n",
        "\n",
        "$$\\huge Y_{it}=\\alpha_i+\\beta X_{it}+\\epsilon_{it}$$\n",
        "\n",
        "Where:\n",
        "* $X_{it}$ are the independent variables (e.g. population and unemployment) whose values vary over time.\n",
        "* $\\beta$ is the slope coefficient for variable $x$ (e.g. unemployment). The model assumes that these effects are time-invariant, e.g. the effect of $x$ is the same at same 1 as it is at time 4 (although the value of $x$ can be different at different time periods).\n",
        "* $\\alpha_i$ and $\\epsilon_{it}$ are both error terms. $\\epsilon_{it}$ is different for each individual at each point in time. $\\alpha_i$ only varies across individuals but not across time. We can think of $\\alpha_i$ as representing the effects of all the time invariant/stable variables that have NOT been included in the model. So, given that we have 6 time periods for each county then the six records for county 1 would all have the same value for $\\alpha_1$, the six records for county 2 would all have the same value for $\\alpha_2$, etc. But, $\\epsilon_{it}$ is free to be different for every case at every time period.\n",
        "\n",
        "A fixed effect regression allows us to account for $\\alpha_i$ through a technique called **demeaning**\n",
        "\n",
        ">**Demeaning**: After demeaning, all variables for all cases have a mean of 0. That means that all the between-subject variability has been eliminated. All that is left is the within-subject variability. So, with a fixed effects model, we are analyzing what causes individualâ€™s values to change across time. Variables whose values do not change (like race or gender) cannot cause changes across time (unless their effects change across time as well). However, whatever effect they have at one time is the same effect that they have at other times, so the effects of such stable characteristics are controlled.\n",
        "\n",
        "In essence, you can picture this as allowing you to draw a separate regression line through each set of observations from the same group in your data (in this case, one county over time); however, while the *intercept* of these lines can vary (their absolute position), they will all have the same *slope* and will therefore be parallel. This is important, as we want to find one slope-- one common effect of x-- that fits *all* groups."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vgzaGVhWvtEk"
      },
      "source": [
        "Run the command below to install the library."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lRbhzoJZvtEk"
      },
      "outputs": [],
      "source": [
        "!pip install linearmodels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pQSVNzb2vtEk"
      },
      "outputs": [],
      "source": [
        "from linearmodels import PanelOLS\n",
        "from linearmodels import RandomEffects\n",
        "import statsmodels.formula.api as smf\n",
        "from linearmodels.panel import compare\n",
        "\n",
        "df_c=df_c.set_index(['county_fips','year']) # set the index to the county fips code and the year\n",
        "panel = PanelOLS.from_formula('r_votes ~ 1  + population + unemployment  + EntityEffects',df_c).fit() # run a fixed effects model\n",
        "print(compare({'Fixed Effects': panel,}, stars=True)) # print the model formatted as a regression table"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tKTFBfnSvtEk"
      },
      "source": [
        "When accounting for time-invariant differences between counties, the effect of population remains negative. This suggests that counties in which the population is *decreasing* tend to experience an increase in republican voteshare. More specifically, for every 1000 people that leave a county, republican voteshare increases by 0.06%.\n",
        "\n",
        "The really interesting part of this regression table, however, is the coefficient on the unemployment variable, which is now positive. This suggests that-- once we account for the differences between counties-- an increase in the unemployment rate *within* a county is *positively* associated with republican voteshare. Indeed, a 1% increase in the unemployment rate leads to a 0.28% increase in republican voteshare.\n",
        "\n",
        "This regression output even gives us three separate $R^2$ values-- one for between-variation, another for within, and one overall."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QQbrkIg_vtEk"
      },
      "source": [
        "---------------------------\n",
        "## 2. Difference in Differences\n",
        "\n",
        "One of the reasons that we observe a signficant relationship between unemployment and voting behaviour in last week's workshop is that the Republican and Democratic parties have opposing views on what to do about unemployment. Democratic lawmakers have historically been in favour of increasing the minimum wage to benefit low-income workers, while Republicans have generally opposed this on the basis that it would hurt these very workers by increase unemployment. Indeed, classical economic theory holds that an increase in wages would lead to a reduction in employment; A business that makes $100k in revenue per year and spends all of it on employing 20 people can't suddenly start paying their workers double their salaries-- unless it fires half of its workers. This is obviously a simplified model though-- minimum wage laws typically don't double wages, and businesses don't operate at-cost, they turn a profit which they could use to pay their workers more. In the rest of this workshop, we're going to be investigating this question empirically:\n",
        "\n",
        "### Do minimum wage laws increase unemployment?\n",
        "\n",
        "Note that this is a *causal* question; i'm not asking if they're correlated-- i'm asking if one causes the other. The burden of proof here is much higher than observing correlations, and we have to think seriously about **endogeneity**. In partiuclar, we need to account for the influence of omitted variables (e.g. a recession, or the economic composition of a state), the potential for reverse causality (states implementing minimum wage laws in response to unemployment crises), and selection bias.\n",
        "\n",
        "In a lab, you can conduct causal inference by running an experiment. You can randomly select individuals, split them into a control group and a treatment group, measure their values in an outcome variable prior to a treatment, administer a treatment, and measure their respective values after the treatment. If you observe a change in the outcome variable in the treatment group after having administered the treatment, you can interpert that as the causal effect of treatment. This is because we're able to make a plausible argument that the **control group can act as a counterfactual (a stand-in) for the treatment group in the absence of treatment**. Both groups had the same values before the treatment, then the only thing that changed between them was the treatment, so if we observe a change in the outcome variable, it must be due to treatment.\n",
        "\n",
        "In the real world, we rarely get to run expermients of this kind. Instead, we have to hunt for **natural experiments**: situations in which there is a **treatment** which we're interested in measuring the effect of, and two groups that can plausibly act as a treatment and control group.\n",
        "\n",
        "> **[Difference in Difference](https://www.publichealth.columbia.edu/research/population-health-methods/difference-difference-estimation#:~:text=DID%20relies%20on%20a%20less,individual%20level%20is%20not%20possible.)** is a quasi-experimental design that makes use of longitudinal data from treatment and control groups to obtain an appropriate counterfactual to estimate a causal effect. DID is typically used to estimate the effect of a specific intervention or treatment (such as a passage of law, enactment of policy, or large-scale program implementation) by comparing the changes in outcomes over time between a population that is enrolled in a program (the intervention group) and a population that is not (the control group).\n",
        "\n",
        "The Difference in Difference model can be estimated as a simple regression model of the following form:\n",
        "\n",
        "$$\\huge Y_{it} = \\beta_0 + \\beta_1 Treatment_i + \\beta_2 Post_t + \\beta_3 (Treatment_i \\times Post_t) + \\varepsilon_{it}$$\n",
        "\n",
        "- $Treatment_i$ is 0 for the control group and 1 for the treatment group\n",
        "- $Post_t$ is 0 for before and 1 for after\n",
        "\n",
        "we can insert the values of $Treatment$ and $Post$ using the table below and see that coefficient ($\\beta_3$) of the interaction of $Treatment$ and $Post$ is the Difference in Differences (DID) estimator:\n",
        "\n",
        "[Card and Krueger (1994)](https://davidcard.berkeley.edu/papers/njmin-aer.pdf) found one such natural experiment, allowing them to estimate the causal effect of an increase in the state minimum wage on unemployment using a DiD model; In 1992, New Jersey raised the state minimum wage from \\$4.25 to \\$5.05 while the minimum wage in neighbouring Pennsylvania stayed the same at \\$4.25.\n",
        "   \n",
        "* Treatmeng Group: New Jersey\n",
        "* Control Group: Pennsylvania\n",
        "* Pre-Treatment Period: before 1992\n",
        "* Post-Treatment Period: after 1992\n",
        "\n",
        "They conducted a survey of 384 fast-food restaurants across both states, right before and right after the law came into effect in New Jersey, asking them how many people they employed. They ran a Difference-in-Differences model, and found that the coefficient $\\beta_3$ was positive but not statistically significant. In other words, the average total employees per restaurant *increased* after the minimum wage increased, but this could have been due to random chance.\n",
        "\n",
        "That was a long time ago. Things have changed since then, including the fact that we have access to a lot more data and computational power. Let's see if we can replicate Card and Krueger's results with more recent data. I've downloaded data on unemployment, minimum wage levels, and Gross Domestic Product at the state level going back to 1976. Let's have a look at minimum wages in New Jersey and Pennsylvania over time:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bOz4BUH2vtEk"
      },
      "outputs": [],
      "source": [
        "df_s=pd.read_csv('https://storage.googleapis.com/qm2/wk10/state_data.csv', parse_dates=['date']) # read in the state-level data\n",
        "did=df_s[df_s['state'].isin(['pennsylvania', 'new jersey'])] # subset the data to only include pennsylvania and new jersey\n",
        "\n",
        "px.line(did, x='date', y='minwage', color='state', title=\"Minimum Wages in New Jersey and Pennsylvania\") # plot the minimum wage over time"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h90xApHwvtEk"
      },
      "source": [
        "The plot above sort of looks like a set of descending staircases; this is for two reasons. The plateaus exist because each row in the dataframe `df_s` is the value of a state in a given *month*, but we only have minimum wage data for every *year*. So we get 12 consecutive values of minimum wage every year. The reason that the staircases are descending is because these minimum wages are adjusted for inflation. No matter where you're from, you've probably heard a grandparent say something along the lines of \"My parents would send me to the shops with 25 cents to buy groceries for the week\", but now it costs Â£9 for a bag of chips. That's inflation-- every year things tend to get slightly more expensive, so if the same *absolute* minimum wage actually diminishes in \"real\" terms, which is what the variable `minwage` measures. Incidentally, this is one of the main reasons University staff have been on [strike](https://www.ucu.org.uk/article/11830/University-staff-pay-cut-by-20-new-figures-show). Anyway. Back to minimum wages.\n",
        "\n",
        "This plot shows that for the past fifty years, New Jersey and Pennsylvania have had largely similar minimum wage policies. There have been a couple moments of divergence, including in the 1990s when the Card and Krueger study was conducted. However, the biggest divergence actually started taking place in 2014 when New Jersey seems to have begun taking a wildly different approach. While Pennsylvania has had the same minimum wage since 2008 (and therefore seen a decline in inflation-adjusted wages), New Jersey has raised the minimum wage significantly twice. In 2020, New Jersey's minimum wage was around 50% higher than Pennsylvania's. We can exploit the fact that these two states have historically had similar minimum wage laws but have recently experienced a big divergence to see if that change in minimum wages has resulted in a change in employment levels.\n",
        "\n",
        "Our Difference-in-Differences setup is as follows:\n",
        "\n",
        "$$\\large Unemployment_{state, year} = \\beta_0 + \\beta_1 Treatment_{state} + \\beta_2 Post_{year} + \\beta_3 (Treatment_{state} \\times Post_{year}) + \\beta_4 GDP_{state,year} + \\varepsilon_{it}$$\n",
        "\n",
        "* New Jersey is the **treatment group**\n",
        "* Pennsylvania is the **control group**\n",
        "* Years before 2014 is the **pre-treatment period**\n",
        "* Years after 2014 is the **post-treatment period**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3QedpATFvtEl"
      },
      "outputs": [],
      "source": [
        "did['post']=np.where(did['date']>='2014-01-01',1,0) # create a variable that is 1 if the date is after the minimum wage increase and 0 otherwise\n",
        "did['treatment']=np.where(did['state']=='new jersey',1,0) # create a variable that is 1 if the state is new jersey (i.e., the treatment group) and 0 for pennsylvania (the control group)\n",
        "did['post_treatment']=did['post']*did['treatment'] # create a variable that is 1 if the date is after the minimum wage increase and the state is new jersey and 0 otherwise"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V9YAmFSxvtEl"
      },
      "source": [
        "Before we proceed with the analysis, though, we need to satisfy two assumptions that will allow us to argue that Pennsylvania can act as a valid control group for New Jersey:\n",
        "\n",
        "1. No simultaneous treatments:\n",
        "    * If, for example, New Jersey suddenly entered a massive recession in 2014 as well, we couldn't really argue that resulting effects on employment are due solely to the minimum wage law. To account for this, we'll be including state-level GDP as an additional independent variable in our DiD model.\n",
        "2. Parallel Trends:\n",
        "    * Both states have to have been experiencing similar trends in the **dependent variable** (unemployment) prior to the treatment (minimum wage law). If they were trending in opposite directions for unobserved reasons, ensuing differences in unemployment may be due to those unobserved reasons rather than the treatment.\n",
        "    * We can check this by plotting the dependent variable for both groups over time, and indicating the timing of the treatment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jG-bYF7jvtEl"
      },
      "outputs": [],
      "source": [
        "did=did[(did['date']>='2008-01-01') & (did['date']<='2020-01-01')]\n",
        "sns.lineplot(data=did,x='date',y='unemployment',hue='state')\n",
        "plt.axvline(pd.to_datetime('2014-01-01'),color='black',linestyle='dashed', label='NJ Minimum Wage Increase')\n",
        "plt.title('Unemployment in Pennsylvania and New Jersey')\n",
        "plt.legend()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PXKiT-_QvtEl"
      },
      "source": [
        "This plot shows a big spike in unemployment occurring for both Pennsylvania and New Jersey as a result of the 2008 financial crisis. New jersey had a higher unemployment rate than Pennsylvania, but their trends are largely parallel and decreasing after 2012. In the years following the minimum wage law, New Jersey's unemployment rate actually dips below Pennsylvania's for the first time in years. Let's look at this in the form of boxplots:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hxNapXTivtEl"
      },
      "outputs": [],
      "source": [
        "did['category']=did['treatment'].astype(str)+did['post'].astype(str) # this variable is just for the plot below\n",
        "sns.boxplot(x='category', y='unemployment', hue='treatment', data=did).set_xticklabels([\"Pre x Treatment\", \"Pre x Control\",'Post x Treatment','Post x Control'])\n",
        "plt.xlabel('')\n",
        "plt.title('Unemployment Rates by Treatment and Post Treatment')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R1aLiJVivtEl"
      },
      "source": [
        "This plot is fascinating in and of itself. The two box plots on the left show the unemployment values of the counties prior to the minimum wage law in 2014, while the two on the right show their values after the minimum wage increases.  Pennsylvania (the \"control\" group) is colored in blue, and New Jersey (the \"treatment\" group) is colored orange. Prior to the minimum wage increase in 2014, Pennsylvania (blue) has a lower unemployment rate than New Jersey (orange). In the years following New Jersey's passage of the minimum wage law, New Jersey actually has a *lower* unemployment rate than Pennsylvania! This is the only boxplot where the \"treatment\" (a minimum wage law) is being applied, and it has the lowest unemployment rate.\n",
        "\n",
        "Let's see if this difference is statistically signfiicant, and calculate a treatment effect:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t-qaAL6svtEl"
      },
      "outputs": [],
      "source": [
        "did_model = ols('unemployment ~  post + treatment + post_treatment', did).fit()\n",
        "print(did_model.summary())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t_UzAoGUvtEl"
      },
      "source": [
        "There are some really interesting results from this model-- let's interpret the coefficients one by one.\n",
        "\n",
        "* `gdp`: GDP is inversely related to unemployment. This makes sense: GDP basically measures the total amount of economic activity, so more economic activity = more employment.\n",
        "* `post`: this coefficient is negative, but statistically insignificant at the 0.05 level; it indicates that unemployment *generally* decreased for both groups, but that this could be due to random chance.\n",
        "* `treatment`: again negative but insignficant, meaning that there is no significant difference in unemployment levels between NJ and PA over the entire period.\n",
        "* `post_treatment`: this is our difference-in-differences estimator, and reflects the causal effect of treatment. It is negative and statistically significant. If we believe that the asusmptions of our model are satisfied, we can claim that:\n",
        "    * **The introduction of a minimum wage in New Jersey led to a 1.95% decrease in unemployment relative to Pennsylvania**\n",
        "\n",
        "This is a bold claim. We should do our best to back it up. Notice that i've sort of arbitrarily chosen a window of dates around the minimum wage law-- maybe this result is a fluke, due to the timespan ive chosen.\n",
        "\n",
        "To address this concern, I'll run the same model 10 times, starting with a really small time window-- just one year on either side of the law-- and progressively expand it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O40Pnb0IvtEl"
      },
      "outputs": [],
      "source": [
        "models=[] # create empty list to store the models\n",
        "names=[] # create empty list to store the names of the models\n",
        "\n",
        "for window in range(1,10): # loop through years from 2000 to 2020 in increments of 4\n",
        "    did=df_s[(df_s['date']>=str(2014-window)+'-01-01') & (df_s['date']<=str(2014+window)+'-01-01') & df_s['state'].isin(['pennsylvania', 'new jersey'])] # subset the data within the window of interest around 2014\n",
        "    did['post']=np.where(did['date']>='2014-01-01',1,0) # create a dummy variable indicating the period after the minimum wage increase\n",
        "    did['treatment']=np.where(did['state']=='new jersey',1,0) # create a dummy variable for treatment\n",
        "    did['post_treatment']=did['post']*did['treatment'] # create an interaction term between the post and treatment variables\n",
        "    did_model = ols('unemployment ~ gdp+ post + treatment + post_treatment', did).fit() # run the difference in difference model\n",
        "\n",
        "    models.append(did_model) # append the model to the list of models\n",
        "    names.append('Â± '+str(window)+' Year') # append the name of the model to the list of names\n",
        "\n",
        "table=summary_col( # create a regression table\n",
        "    models, # pass the models to the summary_col function\n",
        "    stars=True, # add stars denoting the p-values of the coefficient to the table; * p<0.05, ** p<0.01, *** p<0.001\n",
        "    float_format='%0.3f', # set the decimal places to 3\n",
        "    model_names=names, # set the names of the model\n",
        "    info_dict = {\"N\":lambda x: \"{0:d}\".format(int(x.nobs))}) # add the number of observations to the table\n",
        "\n",
        "print(table) # print the table\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yh5JQ3hNvtEl"
      },
      "source": [
        "The row we're mainly interested in is the `post_treatment` coefficient, the treatment effect. It remains significant and negative in all time periods smaller than 8 years, after which point it becomes insignificant;\n",
        "\n",
        "How do you think this affects our conclusion?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I0IJWANG-S8X"
      },
      "source": [
        "This analysis serves as a crucial robustness check with two key findings.\n",
        "\n",
        "First, the negative causal effect of minimum wage on unemployment remains statistically significant across time windows in the short-to-medium term (from 7 years before to 7 years after treatment). This demonstrates that the observed unemployment decrease in New Jersey relative to Pennsylvania is robust across various temporal specifications, not merely an artifact of the chosen time frame.\n",
        "\n",
        "Second, the effect becomes insignificant beyond 8 years, suggesting that long-term impacts either dissipate or become obscured by other factors. This indicates caution is warranted when making claims about very long-term minimum wage effects"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L9SH49V4vtEm"
      },
      "source": [
        "# Assessed Question\n",
        "\n",
        "1. Find the state with the largest increase in minimum wage in the 1990s. This will be our treatment group.\n",
        "2. Set a 5 year window on either side of the treatment date\n",
        "3. Make a parallel trends plot using Arizona as a control group\n",
        "4. Control for the cost of living using the CPI variable.\n",
        "5. Run a difference in differences model.\n",
        "\n",
        "What was the percentage change in unemployment that resulted from the introduction of a minimum wage in this case? Is the difference statistically significant?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5iNDiYA3Ly9N"
      },
      "source": [
        "First, I need to filter the  `df_s` DataFrame to include only the years between 1990 and 1999 (inclusive) to focus on the 1990s. Then, I will calculate the yearly mean minimum wage for each state to prepare for calculating the year-over-year change."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ae6f9287"
      },
      "outputs": [],
      "source": [
        "df_s_90s = df_s[(df_s['date'].dt.year >= 1990) & (df_s['date'].dt.year <= 1999)].copy()\n",
        "df_s_90s['year'] = df_s_90s['date'].dt.year\n",
        "df_s_90s_yearly = df_s_90s.groupby(['state', 'year'])['minwage'].mean().reset_index()\n",
        "\n",
        "print(\"Filtered data for 1990s and yearly mean minwage calculated.\")\n",
        "print(df_s_90s_yearly.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "477a3047"
      },
      "source": [
        "I will now iterate through the yearly minimum wage data for each state to identify the largest single-year increase in minimum wage during the 1990s (with the corresponding state and year).\n",
        "\n",
        "As a result, the treatment state and year, as per the subtask instructions, will be determined.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dec5735c"
      },
      "outputs": [],
      "source": [
        "max_minwage_increase = -1\n",
        "treatment_state = None\n",
        "treatment_year = None\n",
        "\n",
        "for state in df_s_90s_yearly['state'].unique():\n",
        "    state_data = df_s_90s_yearly[df_s_90s_yearly['state'] == state].sort_values('year').copy()\n",
        "    state_data['minwage_diff'] = state_data['minwage'].diff().fillna(0)\n",
        "\n",
        "    current_max_increase_for_state = state_data['minwage_diff'].max()\n",
        "\n",
        "    if current_max_increase_for_state > max_minwage_increase:\n",
        "        max_minwage_increase = current_max_increase_for_state\n",
        "        treatment_state = state\n",
        "        treatment_year = state_data[state_data['minwage_diff'] == current_max_increase_for_state]['year'].iloc[0]\n",
        "\n",
        "treatment_date = pd.to_datetime(f'{treatment_year}-01-01')\n",
        "\n",
        "print(f\"Identified Treatment State: {treatment_state.title()}\")\n",
        "print(f\"Identified Treatment Year (largest single-year minwage increase in 1990s): {treatment_year}\")\n",
        "print(f\"Magnitude of increase: {max_minwage_increase:.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2152273d"
      },
      "source": [
        "## Preparing DiD Data\n",
        "I will filter the dataset to include only the identified treatment state and Arizona, apply the specified 5-year time window around the treatment date, and then create the `post`, `treatment`, and `post_treatment` variables required for the Difference-in-Differences analysis."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c682a517"
      },
      "outputs": [],
      "source": [
        "control_state = 'arizona'\n",
        "window_years = 5\n",
        "\n",
        "# Filter states\n",
        "did_data = df_s[df_s['state'].isin([treatment_state, control_state])].copy()\n",
        "\n",
        "# Filter by time window (5 years before and 5 years after the treatment year)\n",
        "start_year = treatment_year - window_years\n",
        "end_year = treatment_year + window_years\n",
        "did_data = did_data[(did_data['date'].dt.year >= start_year) & (did_data['date'].dt.year <= end_year)].copy()\n",
        "\n",
        "# Create DiD variables\n",
        "did_data['post'] = (did_data['date'] >= treatment_date).astype(int)\n",
        "did_data['treatment'] = (did_data['state'] == treatment_state).astype(int)\n",
        "did_data['post_treatment'] = did_data['post'] * did_data['treatment']\n",
        "\n",
        "# Ensure 'date' is datetime for plotting, though it should already be from df_s\n",
        "did_data['date'] = pd.to_datetime(did_data['date'])\n",
        "\n",
        "print(\"DiD data prepared with treatment, control, pre/post, and interaction variables.\")\n",
        "print(did_data.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "24b40d4d"
      },
      "source": [
        "## Plot Parallel Trends\n",
        "To visually assess the parallel trends assumption, I will create a line plot of unemployment rates for the treatment and control states over the specified time window, marking the treatment date."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8458fd64"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(12, 8))\n",
        "sns.lineplot(data=did_data, x='date', y='unemployment', hue='state')\n",
        "plt.axvline(treatment_date, color='black', linestyle='--', label=f'Treatment Date ({treatment_year})')\n",
        "plt.title(f'Unemployment Trends in {treatment_state.title()} (Treatment) and {control_state.title()} (Control)')\n",
        "plt.xlabel('Date')\n",
        "plt.ylabel('Unemployment Rate')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6256e0b2"
      },
      "source": [
        "## Run DiD Regression Model and Interpret Results\n",
        "I will run the OLS regression model as specified, including `gdp` and `cpi` as control variables, and then print the model summary, which will enable extraction and interpretation of the key coefficient for the `post_treatment` interaction term and assessment of its statistical significance.\n",
        "\n",
        "This code dynamically constructs the OLS regression formula by checking for all-NaN columns (`gdp`, `cpi`) and excluding them if necessary. This approach resolves two previous errors: (1) regression failure when `gdp` contained only NaN values for the 1986-1996 window, and (2) `SyntaxError` from improper concatenation when building the formula string with excluded variables."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "regression_formula_terms = []\n",
        "\n",
        "# Dynamically add control variables if they are not entirely NaN\n",
        "if 'gdp' in did_data.columns and not did_data['gdp'].isnull().all():\n",
        "    regression_formula_terms.append('gdp')\n",
        "else:\n",
        "    print(\"Warning: 'gdp' column is entirely missing or contains only NaNs in the selected data. It will be excluded from the regression.\")\n",
        "\n",
        "if 'cpi' in did_data.columns and not did_data['cpi'].isnull().all():\n",
        "    regression_formula_terms.append('cpi')\n",
        "else:\n",
        "    print(\"Warning: 'cpi' column is entirely missing or contains only NaNs in the selected data. It will be excluded from the regression.\")\n",
        "\n",
        "# Add core DiD variables\n",
        "regression_formula_terms.extend(['post', 'treatment', 'post_treatment'])\n",
        "\n",
        "# Construct the final formula string with ' + ' separators\n",
        "formula_string = 'unemployment ~ ' + ' + '.join(regression_formula_terms)\n",
        "\n",
        "# Identify variables that will actually be used in the regression for cleaning\n",
        "# Ensure that the dependent variable 'unemployment' is always included\n",
        "variables_in_formula = ['unemployment'] + regression_formula_terms\n",
        "\n",
        "# Drop rows with NaN values only for the variables included in the final formula\n",
        "did_data_for_ols = did_data.dropna(subset=variables_in_formula)\n",
        "\n",
        "if did_data_for_ols.empty:\n",
        "    print(\"Error: No valid data points remain for regression after handling missing values. Cannot run OLS model.\")\n",
        "else:\n",
        "    did_model_final = ols(formula_string, data=did_data_for_ols).fit()\n",
        "    print(\"\\nDifference-in-Differences Regression Results:\")\n",
        "    print(did_model_final.summary())\n",
        "\n",
        "    did_effect = did_model_final.params['post_treatment']\n",
        "    p_value = did_model_final.pvalues['post_treatment']\n",
        "    is_significant = p_value < 0.05 # Using a common 0.05 significance level\n",
        "\n",
        "    # Calculate percentage change based on average unemployment in control group pre-treatment\n",
        "    control_pre_unemployment = did_data_for_ols[(did_data_for_ols['state'] == control_state) & (did_data_for_ols['post'] == 0)]['unemployment'].mean()\n",
        "\n",
        "    percentage_change = 0\n",
        "    if control_pre_unemployment != 0 and not pd.isna(control_pre_unemployment):\n",
        "        percentage_change = (did_effect / control_pre_unemployment) * 100\n",
        "    else:\n",
        "        print(\"\\nWarning: Average unemployment in control group pre-treatment is zero or NaN, cannot calculate percentage change.\")\n",
        "\n",
        "    summary_message = f\"\"\"\n",
        "Difference-in-Differences Analysis Summary for the Assessed Question:\n",
        "\n",
        "1.  **Treatment State Identified:** {treatment_state.title()}\n",
        "    *   **Treatment Date:** {treatment_year} (the year of the largest single-year minimum wage increase in the 1990s for this state).\n",
        "\n",
        "2.  **Estimated Causal Effect of Minimum Wage Increase on Unemployment:**\n",
        "    *   The coefficient for the `post_treatment` interaction term (the DiD estimator) is **{did_effect:.3f} percentage points**.\n",
        "    *   This implies an estimated **{percentage_change:.2f}%** change in unemployment in {treatment_state.title()} relative to {control_state.title()} (control) after the minimum wage increase, compared to before.\n",
        "\n",
        "3.  **Statistical Significance:**\n",
        "    *   The p-value for the `post_treatment` coefficient is: **{p_value:.3f}**.\n",
        "    *   Based on a conventional 0.05 significance level, this effect is **{'statistically significant' if is_significant else 'not statistically significant'}**.\n",
        "\"\"\"\n",
        "    print(summary_message)"
      ],
      "metadata": {
        "id": "Mnnz7iv_zNj8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "44c809c2"
      },
      "source": [
        "The `post_treatment` coefficient of -1.1961 indicates that the minimum wage increase in Iowa led to an approximate 1.20 percentage point decrease in unemployment relative to Arizona, after controlling for `cpi` and pre-existing trends. This effect is highly statistically significant (p < 0.001).\n",
        "\n",
        "Realizing the question specifically asked for percentage change (not percentage points), I calculated the relative effect using Arizona's pre-treatment unemployment rate as the baseline. The average unemployment rate in Arizona before Iowa's minimum wage increase was 6.0827%. Dividing the DID coefficient (-1.196) by this baseline and multiplying by 100 yields: (-1.196 / 6.0827) Ã— 100 = -19.66%. This indicates Iowa's unemployment rate decreased by 19.66% relative to Arizona's baseline unemployment as a result of the minimum wage increase."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "claymodel",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}